{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finfraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.copy()\n",
    "\n",
    "# #Ivde extracting nameOrig and nameDest where C is present\n",
    "# data['OrigC']=data['nameOrig'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\n",
    "# data['DestC']=data['nameDest'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\n",
    "\n",
    "# #Ivde creating new feature for transfer and cash_out\n",
    "# data['TRANSFER']=data['type'].apply(lambda x: 1 if x=='TRANSFER' else 0)\n",
    "# data['CASH_OUT']=data['type'].apply(lambda x: 1 if x=='CASH_OUT' else 0)\n",
    "\n",
    "droplist=['isFlaggedFraud','type','nameDest','nameOrig']\n",
    "\n",
    "#Preprocessing function \n",
    "def data_preprocessing(data):\n",
    "    \n",
    "    #Ivde extracting nameOrig and nameDest where C is present\n",
    "    data['OrigC']=data['nameOrig'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\n",
    "    data['DestC']=data['nameDest'].apply(lambda x: 1 if str(x).find('C')==0 else 0)\n",
    "\n",
    "    #Ivde creating new feature for transfer and cash_out\n",
    "    data['TRANSFER']=data['type'].apply(lambda x: 1 if x=='TRANSFER' else 0)\n",
    "    data['CASH_OUT']=data['type'].apply(lambda x: 1 if x=='CASH_OUT' else 0)\n",
    "    \n",
    "    #Ivde extracting error in account balances\n",
    "    data['Amount Error']=(abs(data['oldbalanceOrg']-data['newbalanceOrig'])-data['amount'])\n",
    "       \n",
    "    data = data.drop(labels=droplist,axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ivde extracting error in account balances\n",
    "#data['Amount Error']=(abs(data['oldbalanceOrg']-data['newbalanceOrig'])-data['amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droplist=['isFlaggedFraud','type','nameDest','nameOrig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_result(model,x_test,y_test):\n",
    "    y_pred=model.predict(x_test)\n",
    "    print('F1-score :',(f1_score(y_test,y_pred)))\n",
    "    print('Confusion_matrix : ')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(\"accuracy_score : \", end = '')\n",
    "    print(accuracy_score(y_test,y_pred))\n",
    "    print(\"classification_report\")\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = data.drop(labels=droplist,axis=1)\n",
    "\n",
    "df = data_preprocessing(df)\n",
    "\n",
    "X = df.drop('isFraud',axis=1)\n",
    "Y = df.isFraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3,random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# weights = (Y == 0).sum() / (1.0 * (Y == 1).sum()) # giving class weight\n",
    "# clf = XGBClassifier( scale_pos_weight = weights, n_jobs = 4, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "# print ('Test')\n",
    "# model_result(clf,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "AUPRC : 0.9999988164994575\n",
      "F1 - score : 0.9993028582810476\n",
      "Confusion_matrix : \n",
      "[[2540024       0]\n",
      " [      7    5017]]\n",
      "accuracy_score\n",
      "0.9999972495607156\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   2540024\n",
      "           1       1.00      1.00      1.00      5024\n",
      "\n",
      "    accuracy                           1.00   2545048\n",
      "   macro avg       1.00      1.00      1.00   2545048\n",
      "weighted avg       1.00      1.00      1.00   2545048\n",
      "\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.4,random_state=42, shuffle=False)\n",
    "xgb_model = XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "model_result(xgb_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "AUPRC : 0.9999997607600722\n",
      "F1 - score : 0.9997811337272926\n",
      "Confusion_matrix : \n",
      "[[1904216       0]\n",
      " [      2    4568]]\n",
      "accuracy_score\n",
      "0.9999989522136059\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1904216\n",
      "           1       1.00      1.00      1.00      4570\n",
      "\n",
      "    accuracy                           1.00   1908786\n",
      "   macro avg       1.00      1.00      1.00   1908786\n",
      "weighted avg       1.00      1.00      1.00   1908786\n",
      "\n",
      "Wall time: 15min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3,random_state=42, shuffle=False)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "model_result(rf_model,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('finfraud.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['isFraud']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_preprocessing(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = dataset.drop('isFraud',axis=1)\n",
    "y_data = dataset['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC : 1.0\n",
      "F1 - score : 0.9975588917368485\n",
      "Confusion_matrix : \n",
      "[[   0    0]\n",
      " [  40 8173]]\n",
      "accuracy_score\n",
      "0.9951296724704737\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00      8213\n",
      "   macro avg       0.50      0.50      0.50      8213\n",
      "weighted avg       1.00      1.00      1.00      8213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_result(xgb_model, X_data, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUPRC : 1.0\n",
      "F1 - score : 0.9998782269849001\n",
      "Confusion_matrix : \n",
      "[[   0    0]\n",
      " [   2 8211]]\n",
      "accuracy_score\n",
      "0.9997564836235237\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      1.00      1.00      8213\n",
      "\n",
      "    accuracy                           1.00      8213\n",
      "   macro avg       0.50      0.50      0.50      8213\n",
      "weighted avg       1.00      1.00      1.00      8213\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_result(rf_model, X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBOOST MODEL\n",
    "filename = 'xgboost.sav'\n",
    "pickle.dump(xgb_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST MODEL\n",
    "filename = 'randomforest.sav'\n",
    "pickle.dump(rf_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING FUNCTION\n",
    "# filename = 'preprocessing.sav'\n",
    "# pickle.dump(data_preprocessing, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
